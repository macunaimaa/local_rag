{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain_openai import OpenAI \n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you want to use Local embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joao/miniconda3/envs/finetune_llm/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy  as np\n",
    "class LocalEmbeddings(Embeddings):\n",
    "    def __init__(self, model_name=\"all-MiniLM-L6-v2\"):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        \n",
    "    def embed_documents(self, texts):\n",
    "        return np.array(self.model.encode(texts))\n",
    "    \n",
    "    def embed_query(self, text):\n",
    "        return np.array(self.model.encode([text])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"Honda_2020.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tratando os dados localmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joao/miniconda3/envs/finetune_llm/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#transforma tudo extraido em uma lista com apenas os textos por chunk\n",
    "texts = [doc.page_content for doc in docs]\n",
    "metadata = [doc.metadata for doc in docs]\n",
    "\n",
    "model = LocalEmbeddings()\n",
    "\n",
    "#transforma os embeddings e textos em um vector database\n",
    "library = FAISS.from_texts(texts=texts,embedding = model, metadatas=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Query1 = \"Me explique sobre a linha de Bordo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'Honda_2020.md'}, page_content='**B**'),\n",
       " Document(metadata={'source': 'Honda_2020.md'}, page_content='com Bluetooth[®].'),\n",
       " Document(metadata={'source': 'Honda_2020.md'}, page_content='Bluetooth[®]........................................ 9-42\\nInformações Legais do Apple'),\n",
       " Document(metadata={'source': 'Honda_2020.md'}, page_content='iPod[®].\\n\\nnovamente)')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Query_Answer = library.similarity_search(Query1)\n",
    "Query_Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_n_scores = library.similarity_search_with_score(Query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'Honda_2020.md'}, page_content='**B**'),\n",
       "  1.305159),\n",
       " (Document(metadata={'source': 'Honda_2020.md'}, page_content='com Bluetooth[®].'),\n",
       "  1.3274362),\n",
       " (Document(metadata={'source': 'Honda_2020.md'}, page_content='Bluetooth[®]........................................ 9-42\\nInformações Legais do Apple'),\n",
       "  1.3391099),\n",
       " (Document(metadata={'source': 'Honda_2020.md'}, page_content='iPod[®].\\n\\nnovamente)'),\n",
       "  1.4186926)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_n_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = library.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting it up with Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1056106/1214122809.py:9: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embeddings = OllamaEmbeddings(model='llama3.2:latest')\n",
      "/tmp/ipykernel_1056106/1214122809.py:11: LangChainDeprecationWarning: This class is deprecated. See the following migration guides for replacements based on `chain_type`:\n",
      "stuff: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain\n",
      "map_reduce: https://python.langchain.com/docs/versions/migrating_chains/map_reduce_chain\n",
      "refine: https://python.langchain.com/docs/versions/migrating_chains/refine_chain\n",
      "map_rerank: https://python.langchain.com/docs/versions/migrating_chains/map_rerank_docs_chain\n",
      "\n",
      "See also guides on retrieval and question-answering here: https://python.langchain.com/docs/how_to/#qa-with-rag\n",
      "  combine_documents_chain = load_qa_chain(llm=llm, chain_type=\"stuff\")\n",
      "/tmp/ipykernel_1056106/1214122809.py:14: LangChainDeprecationWarning: This class is deprecated. Use the `create_retrieval_chain` constructor instead. See migration guide here: https://python.langchain.com/docs/versions/migrating_chains/retrieval_qa/\n",
      "  qa = RetrievalQA(combine_documents_chain=combine_documents_chain, retriever=library.as_retriever())\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "\n",
    "llm = ChatOllama(model='llama3.2:latest')\n",
    "\n",
    "# Initialize the embeddings model\n",
    "embeddings = OllamaEmbeddings(model='llama3.2:latest')\n",
    "\n",
    "combine_documents_chain = load_qa_chain(llm=llm, chain_type=\"stuff\")\n",
    "\n",
    "# Initialize the RetrievalQA chain\n",
    "qa = RetrievalQA(combine_documents_chain=combine_documents_chain, retriever=library.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Query2 = \"whats was the world's first electronic digital programmable computer?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = qa.invoke(Query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': \"whats was the world's first electronic digital programmable computer?\",\n",
       " 'result': \"I don't know, but I can tell you that Charles Babbage is often credited with designing the first mechanical computer, the Difference Engine and Analytical Engine, in the early 19th century. \\n\\nHowever, some historians argue that the Colossus machine, built in 1943 during World War II at Bletchley Park, was a precursor to modern electronic computers, as it was used for code-breaking purposes.\\n\\nThe first electronic digital programmable computer is generally considered to be ENIAC (Electronic Numerical Integrator and Computer), which was completed in 1946 by John Mauchly and J. Presper Eckert at the University of Pennsylvania.\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
